{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thr required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Declare the directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory :  c:\\Users\\Avishka Sandeepa\\OneDrive - University of Moratuwa\\GitHub\\Traffic-Signs-Recognition\\main\\codes\n",
      "Current working directory :  C:\\Users\\Avishka Sandeepa\\OneDrive - University of Moratuwa\\GitHub\\Traffic-Signs-Recognition\\main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print (\"Current working directory : \" , current_directory)\n",
    "\n",
    "# define the directory of data set\n",
    "data_direcory = \"C:/Users/Avishka Sandeepa/OneDrive - University of Moratuwa/GitHub/Traffic-Signs-Recognition/main\"\n",
    "# chane the current directory to the data directory\n",
    "os.chdir(data_direcory)\n",
    "\n",
    "# chek the working directory again after changing\n",
    "current_directory = os.getcwd()\n",
    "print (\"Current working directory : \" , current_directory)\n",
    "\n",
    "# define the each folder directories for training and testing data\n",
    "train_set = 'Train'\n",
    "test_set = 'Test'\n",
    "\n",
    "num_classes = len(os.listdir(train_set)) # returns the no of classes inside the training folder(0 to 42)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing the Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acess the each and every image\n",
    "\n",
    "img_data =[]\n",
    "img_labels = []\n",
    " \n",
    "for index in range(num_classes):   # address all classes  \n",
    "    path = os.path.join(current_directory,'Train',str(index)) # create the path for each image    \n",
    "    image_names = os.listdir(path) # list containing names of all images for a running class at that point\n",
    "    \n",
    "    \n",
    "    for image in image_names:\n",
    "        img = cv.imread(path + '/' + image, cv.IMREAD_COLOR)\n",
    "        img = cv.resize(img, (32,32)) # resizing all images to one scale\n",
    "        # convert image data into numy array\n",
    "        img = np.array(img) \n",
    "\n",
    "        img_data.append(img)\n",
    "        img_labels.append(index)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 32, 32, 3) (39209,)\n"
     ]
    }
   ],
   "source": [
    "# lets convert above created list into numpy arrays that helps to model to training\n",
    "\n",
    "img_data = np.array(img_data)\n",
    "img_labels = np.array(img_labels)\n",
    "\n",
    "print(img_data.shape, img_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape (26270, 32, 32, 3)\n",
      "val_x.shape (12939, 32, 32, 3)\n",
      "train_y.shape (26270,)\n",
      "val_y.shape (12939,)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation data\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(img_data, img_labels, test_size=0.33, random_state=42, shuffle=True)\n",
    "train_x = train_x/255 \n",
    "val_x = val_x/255\n",
    "\n",
    "print(\"train_x.shape\", train_x.shape)\n",
    "print(\"val_x.shape\", val_x.shape)\n",
    "print(\"train_y.shape\", train_y.shape)\n",
    "print(\"val_y.shape\", val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff9c3df18c39e40a632fe67bd3f2effcf292bf7152cebacfc692487f5f951f29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
